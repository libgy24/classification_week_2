{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import dataset \n",
    "products = pd.read_csv('amazon_baby_subset.csv')\n",
    "\n",
    "# import json file \n",
    "\n",
    "import json \n",
    "with open('important_words.json') as important_words:\n",
    "    important_words = json.load(important_words)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book\n",
       "1    Nature's Lullabies Second Year Sticker Calendar                                                  \n",
       "2    Nature's Lullabies Second Year Sticker Calendar                                                  \n",
       "3    Lamaze Peekaboo, I Love You                                                                      \n",
       "4    SoftPlay Peek-A-Boo Where's Elmo A Children's Book                                               \n",
       "5    Our Baby Girl Memory Book                                                                        \n",
       "6    Hunnt&reg; Falling Flowers and Birds Kids Nursery Home Decor Vinyl Mural Art Wall Paper Stickers \n",
       "7    Blessed By Pope Benedict XVI Divine Mercy Full Color Medal                                       \n",
       "8    Cloth Diaper Pins Stainless Steel Traditional Safety Pin (Black)                                 \n",
       "9    Cloth Diaper Pins Stainless Steel Traditional Safety Pin (Black)                                 \n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display first 10 names in the dataframe\n",
    "products['name'][0:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>26461</td>\n",
       "      <td>26393</td>\n",
       "      <td>26493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26521</td>\n",
       "      <td>26438</td>\n",
       "      <td>26579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  review  rating\n",
       "sentiment                       \n",
       "-1         26461  26393   26493 \n",
       " 1         26521  26438   26579 "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count \n",
    "\n",
    "products.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace empty string with n/a in review column\n",
    "\n",
    "products = products.fillna({'review':''})\n",
    "\n",
    "# remove punctutation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None,string.punctuation)\n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "\n",
    "\n",
    "# for each word in important__words, we compute a count for the number of times the word occurs in the review. \n",
    "# We will store tis count in a separate column (one for each word). The result of this feature processing is a single \n",
    "# column for each word in important_words which keeps a count of the number of times the respective word occurs in \n",
    "# the review text.\n",
    "\n",
    "for word in important_words:\n",
    "    products[word] =products['review_clean'].apply(lambda s: s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column in products to count the number of reviews that contains 'perfect'\n",
    "\n",
    "products['contains_perfect'] =[1 if x>=1 else 0 for x in products['perfect']]\n",
    "\n",
    "# count\n",
    "\n",
    "np.sum(products['contains_perfect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write a function that accept three parameters: dataframe, feature, label\n",
    "\n",
    "def get_numpy_data(dataframe, features, label):\n",
    "    dataframe['constant'] =1\n",
    "    features = ['constant'] + features\n",
    "    features_matrix = dataframe[features].values\n",
    "    label_array = dataframe[label].values\n",
    "    return features_matrix,label_array\n",
    "\n",
    "\n",
    "# Write a function to produce probablistic estimate for p(y_i = +1|x,w)\n",
    "\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    scores = feature_matrix.dot(coefficients)\n",
    "    predictions = 1/(1 + np.exp(np.negative(scores)))\n",
    "    return predictions\n",
    "                     \n",
    "# write a function to produce derivative \n",
    "  \n",
    "def feature_derivative(errors,feature):\n",
    "    derivative = feature.T.dot(errors)\n",
    "    return derivative\n",
    "# write a function that compute the log likelihood\n",
    "                     \n",
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = feature_matrix.dot(coefficients)\n",
    "    lp = np.sum(((indicator-1) * scores)-np.log(1. + np.exp(-scores)))\n",
    "    return lp\n",
    "                     \n",
    "# write a function to fit a logistic regression model using gradient ascent\n",
    "                     \n",
    "def logistic_regression(feature_matrix,sentiment, initial_coefficients,step_size,max_iter):\n",
    "    # initialize vector coefficients to initial_coefficients.\n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    for itr in xrange(max_itr):\n",
    "        coefficients = initial_coefficients\n",
    "        # predict the probability using initial coefficients\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        # compute indicator\n",
    "        indicator = (sentiment == +1)\n",
    "        # compute the errors \n",
    "        errors = indicator - predictions\n",
    "        for i in xrange(len(coefficients)):\n",
    "            derivative = feature_matrix[:,i].T.dot(errors)\n",
    "            coefficients[i] = coefficients[i] + step_size * derivative\n",
    "        \n",
    "        # checking whether log likelihood is increasing\n",
    "                     \n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % (int(np.ceil(np.log10(max_iter))),itr,lp)\n",
    "    return coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix,sentiment = get_numpy_data(products,important_words,'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_coefficients = np.zeros(194)\n",
    "step_size = 1e-7\n",
    "max_itr = 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -35264.09713332\n",
      "iteration   1: log likelihood of observed labels = -35259.68571379\n",
      "iteration   2: log likelihood of observed labels = -35255.27786368\n",
      "iteration   3: log likelihood of observed labels = -35250.87357844\n",
      "iteration   4: log likelihood of observed labels = -35246.47285354\n",
      "iteration   5: log likelihood of observed labels = -35242.07568446\n",
      "iteration   6: log likelihood of observed labels = -35237.68206667\n",
      "iteration   7: log likelihood of observed labels = -35233.29199568\n",
      "iteration   8: log likelihood of observed labels = -35228.90546699\n",
      "iteration   9: log likelihood of observed labels = -35224.52247612\n",
      "iteration  10: log likelihood of observed labels = -35220.14301858\n",
      "iteration  11: log likelihood of observed labels = -35215.76708993\n",
      "iteration  12: log likelihood of observed labels = -35211.39468570\n",
      "iteration  13: log likelihood of observed labels = -35207.02580145\n",
      "iteration  14: log likelihood of observed labels = -35202.66043273\n",
      "iteration  15: log likelihood of observed labels = -35198.29857514\n",
      "iteration  20: log likelihood of observed labels = -35176.54179970\n",
      "iteration  30: log likelihood of observed labels = -35133.28906477\n",
      "iteration  40: log likelihood of observed labels = -35090.38049497\n",
      "iteration  50: log likelihood of observed labels = -35047.81185992\n",
      "iteration  60: log likelihood of observed labels = -35005.57901340\n",
      "iteration  70: log likelihood of observed labels = -34963.67788958\n",
      "iteration  80: log likelihood of observed labels = -34922.10449942\n",
      "iteration  90: log likelihood of observed labels = -34880.85492749\n",
      "iteration 100: log likelihood of observed labels = -34839.92532902\n",
      "iteration 200: log likelihood of observed labels = -34447.42769770\n",
      "iteration 300: log likelihood of observed labels = -34083.14010104\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix,sentiment,initial_coefficients,step_size,max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = predict_probability(feature_matrix,coefficients)\n",
    "scores = feature_matrix.dot(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame({'sentiment':sentiment,\n",
    "                            'prediction':predictions,\n",
    "                             'scores':scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_df['correct_flag'] =[1 if x>0 else -1 for x in prediction_df['scores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40059\n",
      "53072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7548047934880916"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly predicted\n",
    "\n",
    "np.sum(prediction_df['correct_flag'])\n",
    "\n",
    "prediction_df['flag'] = prediction_df['sentiment'] -prediction_df['correct_flag']\n",
    "print np.shape(np.array(list(np.where(prediction_df['flag']==0))))[1]\n",
    "print np.shape(feature_matrix)[0]\n",
    "\n",
    "40059.0/53072.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients = list(coefficients[1:])\n",
    "\n",
    "word_coefficients_tuples = [(word, coefficient) for word,coefficient in zip(important_words, coefficients)]\n",
    "\n",
    "word_coefficients_tuples = sorted(word_coefficients_tuples, key = lambda x:x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
